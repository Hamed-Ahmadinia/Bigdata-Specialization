{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6 - Hamed Ahmadinia \n",
    "1. Use yeast dataset from UCI http://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data\n",
    "2. Remove the first column and use the last column as the target\n",
    "3. Only leave CYT and VAC classes\n",
    "4. Replace [0.3, 0.5, 0.7] in feature 2 to null\n",
    "5. Replace [0.26, 0.36, 0.64] in feature 3 to null\n",
    "6. Split the data\n",
    "\n",
    "7. Impute the data (or not, it's your call)\n",
    "8. Build a outlier detection model to classify VAC from CYT, i.e. 0 from 1\n",
    "9. Build a classifer using sample augmentation techniques to flassify VAC from CYT, i.e. 0 from 1\n",
    "10. Try different methods and hyper paramters\n",
    "\n",
    "11. Report perfromance using F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seting the required environment\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v2    v3    v4   v5   v6    v7    v8  v9\n",
       "0  0.40  0.56  0.17  0.5  0.5  0.49  0.22   1\n",
       "1  0.39  0.60  0.15  0.5  0.0  0.58  0.30   1\n",
       "2  0.42  0.57  0.35  0.5  0.0  0.53  0.25   1\n",
       "3  0.44  0.52  0.11  0.5  0.0  0.50  0.22   1\n",
       "4  0.39  0.50  0.11  0.5  0.0  0.49  0.40   1\n",
       "5  0.40  0.50  0.16  0.5  0.0  0.50  0.22   1\n",
       "6  0.44  0.48  0.22  0.5  0.0  0.51  0.22   1\n",
       "7  0.63  0.42  0.30  0.5  0.0  0.49  0.22   1\n",
       "8  0.53  0.52  0.13  0.5  0.0  0.55  0.22   1\n",
       "9  0.53  0.52  0.15  0.5  0.0  0.58  0.22   1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the dataset \"yeast.data\" and seting whitespace to be used as the sep.\n",
    "# Adiing Prefix to column numbers when no header, e.g. ‘v’ for v0, v1, …\n",
    "data = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data', header=None, delim_whitespace=True, prefix='v')\n",
    "\n",
    "# from the 3th columns of dataframe onwards with all rows\n",
    "data = data.iloc[:,2:]\n",
    "\n",
    "# Removing all classeses from dataframe coloumn v9 with clases except \"CYT\" and \"VAC\"  \n",
    "# we used \".reset_index()\" to reset the index of the DataFrame, and use the default one instead\n",
    "# we used \"drop('index', axis=1)\" to drop labels from ‘index’ and axis=1 along the columns.\n",
    "data = data.loc[(data.v9 == 'VAC')|(data.v9 == 'CYT'), :].reset_index().drop('index', axis=1)\n",
    "\n",
    "# replace value in clases \"CYT\" with 1 and \"VAC\" with 0 in the related columns which is here \"v9\" in our dataframe\n",
    "data=data.replace('CYT', 1)\n",
    "data=data.replace('VAC', 0)\n",
    "\n",
    "# show the first 10 rows for the object based on position\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(493, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replacing [0.3, 0.5, 0.7] in feature 2 to null which is here coulum \"v2\"\n",
    "# replace [0.26, 0.36, 0.64] in feature 3 to null which is here coulum \"v3\"\n",
    "# NaN is short for Not a number. It is used to represent entries that are undefined\n",
    "data[\"v2\"] = data.v2.replace([0.3, 0.5, 0.7], np.nan)\n",
    "data[\"v3\"] = data.v3.replace([0.26, 0.36, 0.64], np.nan)\n",
    "\n",
    "# checking dataframe shape\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe \"yeast.data\"\n",
    "X, y = data.iloc[:,:-1], data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v2    v3    v4   v5   v6    v7    v8\n",
       "0  0.40  0.56  0.17  0.5  0.5  0.49  0.22\n",
       "1  0.39  0.60  0.15  0.5  0.0  0.58  0.30\n",
       "2  0.42  0.57  0.35  0.5  0.0  0.53  0.25\n",
       "3  0.44  0.52  0.11  0.5  0.0  0.50  0.22\n",
       "4  0.39  0.50  0.11  0.5  0.0  0.49  0.40\n",
       "5  0.40  0.50  0.16  0.5  0.0  0.50  0.22\n",
       "6  0.44  0.48  0.22  0.5  0.0  0.51  0.22\n",
       "7  0.63  0.42  0.30  0.5  0.0  0.49  0.22\n",
       "8  0.53  0.52  0.13  0.5  0.0  0.55  0.22\n",
       "9  0.53  0.52  0.15  0.5  0.0  0.58  0.22"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing \"sklearn.impute.KNNImputer\"  in order to imputation for completing missing values using k-Nearest Neighbors.\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# each sample’s missing values are imputed using the mean value from 2 neighbors nearest neighbors found in the training set\n",
    "# we  used ‘uniform’ as uniform weights in which All points in each neighborhood are weighted equally\n",
    "impute = KNNImputer(n_neighbors=2, weights='uniform')\n",
    "\n",
    "# defining X_new as Fit to data, then transform it.\n",
    "X_new = pd.DataFrame(impute.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# show the first 10 rows for \"X_new\" which we defined based on position\n",
    "X_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1,  1,  1, -1,  1,  1, -1,  1,  1,  1,  1, -1,  1,  1,  1,  1,\n",
       "        1,  1,  1, -1,  1,  1, -1,  1, -1,  1, -1,  1,  1, -1, -1,  1,  1,\n",
       "       -1, -1,  1, -1,  1, -1, -1, -1, -1, -1,  1,  1, -1,  1,  1,  1,  1,\n",
       "       -1,  1, -1, -1, -1,  1, -1,  1,  1, -1, -1,  1,  1, -1, -1,  1,  1,\n",
       "        1,  1, -1,  1,  1, -1, -1, -1,  1,  1,  1, -1, -1, -1, -1,  1, -1,\n",
       "        1,  1,  1,  1,  1,  1, -1,  1,  1, -1,  1, -1,  1, -1, -1,  1, -1,\n",
       "       -1,  1, -1,  1, -1,  1,  1,  1, -1, -1,  1, -1, -1,  1,  1,  1, -1,\n",
       "       -1,  1, -1, -1, -1,  1,  1,  1,  1, -1, -1,  1,  1,  1, -1,  1, -1,\n",
       "       -1, -1,  1,  1, -1,  1,  1, -1, -1, -1, -1, -1,  1,  1, -1, -1,  1,\n",
       "       -1,  1,  1,  1,  1, -1,  1, -1, -1, -1,  1,  1, -1, -1,  1, -1,  1,\n",
       "        1, -1,  1,  1, -1,  1,  1,  1,  1,  1, -1,  1, -1, -1,  1, -1, -1,\n",
       "       -1, -1,  1, -1,  1,  1,  1, -1,  1, -1,  1,  1,  1,  1, -1, -1,  1,\n",
       "        1, -1,  1, -1,  1,  1, -1, -1,  1,  1,  1, -1, -1, -1,  1,  1,  1,\n",
       "       -1,  1, -1, -1, -1, -1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1,\n",
       "       -1, -1,  1,  1,  1,  1,  1, -1, -1,  1,  1,  1,  1, -1,  1,  1,  1,\n",
       "       -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1,  1,  1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,\n",
       "       -1, -1,  1, -1,  1, -1,  1, -1,  1,  1,  1, -1, -1,  1,  1,  1, -1,\n",
       "       -1, -1,  1,  1,  1,  1,  1,  1, -1, -1, -1,  1, -1,  1, -1, -1,  1,\n",
       "       -1,  1,  1, -1, -1, -1,  1, -1,  1, -1, -1, -1,  1,  1,  1,  1,  1,\n",
       "        1, -1, -1,  1,  1,  1, -1, -1,  1, -1,  1, -1,  1, -1, -1, -1,  1,\n",
       "        1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1,  1, -1,\n",
       "        1, -1, -1, -1,  1,  1, -1,  1,  1, -1, -1,  1, -1, -1,  1, -1, -1,\n",
       "        1, -1, -1,  1,  1,  1, -1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1, -1, -1,  1,  1, -1,  1, -1, -1, -1, -1, -1,  1, -1, -1,\n",
       "       -1,  1, -1, -1,  1,  1, -1, -1,  1, -1,  1,  1,  1, -1,  1,  1, -1,\n",
       "        1,  1, -1, -1,  1, -1, -1,  1, -1, -1, -1, -1,  1,  1, -1, -1,  1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a outlier detection model to classify VAC from CYT, i.e. 0 from 1\n",
    "# we used sklearn.svm.OneClassSVM as Unsupervised Outlier Detection and estimate the support of a high-dimensional distribution\n",
    "# Importing neClassSVM from sklearn.svm in which LIBSVM is an integrated software for support vector classification\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# fit model in OneClassSVM and Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid is set to 'auto' which uses 1 / n_features.\n",
    "clf = OneClassSVM(gamma='auto').fit(X_new)\n",
    "\n",
    "# The predict method predicts our actual testing dataset with regard to the fitted (training) data \"X_new\"\n",
    "clf.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    463\n",
       "0     30\n",
       "Name: v9, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking series containing counts of unique values.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\programdata\\anaconda3\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.20.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.6.2)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn) (2.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\ProgramData\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# instaling Imbalanced-learn (imported as imblearn )\n",
    "# it is a MIT-licensed library relying on scikit-learn (imported as sklearn )\n",
    "# it provides tools when dealing with classification with imbalanced classes\n",
    "!pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing \"train_test_split\" packeges for Split arrays or matrices into random train and test subsets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# making traning and test sets by spliting data \n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X_new, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of a dummy classifier is: 0.934\n",
      "Balanced accuracy score of a dummy classifier is: 0.500\n",
      "0.979381443298969\n"
     ]
    }
   ],
   "source": [
    "# impoerting cross_validate for evaluate metric(s) by cross-validation and also record fit/score times\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# impoerting DummyClassifier as a classifier that makes predictions using simple rules.\n",
    "# This classifier is useful as a simple baseline to compare with other (real) classifiers.\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Compute the F1 score, also known as balanced F-score or F-measure.\n",
    "# The F1 score can be interpreted as a harmonic mean of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. \n",
    "# The relative contribution of precision and recall to the F1 score are equal\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# define \"dummy_clf\"  with strategy as most_frequent which means always predicts the most frequent label in the training set\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "# We performed a cross-validation evaluation to get an estimate of the test score.\n",
    "# As a baseline, we could use a classifier which will always predict the majority class independently of the features provided.\n",
    "scoring = [\"accuracy\", \"balanced_accuracy\"]\n",
    "cv_result = cross_validate(dummy_clf, xtrain, ytrain, scoring=scoring)\n",
    "print(f\"Accuracy score of a dummy classifier is: {cv_result['test_accuracy'].mean():.3f}\")\n",
    "print(\n",
    "    f\"Balanced accuracy score of a dummy classifier is: \"\n",
    "    f\"{cv_result['test_balanced_accuracy'].mean():.3f}\"\n",
    ")\n",
    "dummy_clf.fit(xtrain, ytrain)\n",
    "print(f1_score(dummy_clf.predict(xtest), ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    96\n",
       "0     3\n",
       "Name: v9, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking series containing counts of unique values.\n",
    "ytest.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We used a dictionary and a list to continuously store the results of our experiments and show them as a pandas dataframe\n",
    "index = []\n",
    "scores = {\"Accuracy\": [], \"Balanced accuracy\": [], \"f1_score\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy classifier</th>\n",
       "      <td>0.931483</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.492308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Accuracy  Balanced accuracy  f1_score\n",
       "Dummy classifier  0.931483                0.5  0.492308"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before to train a real machine learning model, we stored the results obtained with our DummyClassifier\n",
    "index += [\"Dummy classifier\"]\n",
    "\n",
    "# Try different methods and hyper paramters Dummy classifier\n",
    "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
    "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
    "scores[\"f1_score\"].append(f1_score(dummy_clf.predict(xtest), ytest,average='macro'))\n",
    "\n",
    "df_scores = pd.DataFrame(scores, index=index)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy classifier</th>\n",
       "      <td>0.931483</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.492308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic regression</th>\n",
       "      <td>0.931483</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.492308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Balanced accuracy  f1_score\n",
       "Dummy classifier     0.931483                0.5  0.492308\n",
       "Logistic regression  0.931483                0.5  0.492308"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try different methods and hyper paramters Dummy classifier vs LogisticRegression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "index += [\"Logistic regression\"]\n",
    "cv_result = cross_validate(lr_clf, xtrain, ytrain, scoring=scoring)\n",
    "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
    "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
    "lr_clf.fit(xtrain, ytrain)\n",
    "scores[\"f1_score\"].append(f1_score(lr_clf.predict(xtest), ytest,average='macro'))\n",
    "\n",
    "df_scores = pd.DataFrame(scores, index=index)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy classifier</th>\n",
       "      <td>0.931483</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.492308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic regression</th>\n",
       "      <td>0.931483</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.492308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.947269</td>\n",
       "      <td>0.597826</td>\n",
       "      <td>0.744845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Balanced accuracy  f1_score\n",
       "Dummy classifier     0.931483           0.500000  0.492308\n",
       "Logistic regression  0.931483           0.500000  0.492308\n",
       "Random forest        0.947269           0.597826  0.744845"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy classifier vs LogisticRegression vs Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42, n_jobs=2)\n",
    "\n",
    "index += [\"Random forest\"]\n",
    "cv_result = cross_validate(rf_clf, X_new, y, scoring=scoring)\n",
    "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
    "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
    "\n",
    "scores[\"f1_score\"].append(f1_score(rf_clf.fit(xtrain, ytrain).predict(xtest), ytest,average='macro'))\n",
    "\n",
    "df_scores = pd.DataFrame(scores, index=index)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy classifier</th>\n",
       "      <td>0.931483</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.492308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic regression</th>\n",
       "      <td>0.931483</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.492308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.947269</td>\n",
       "      <td>0.597826</td>\n",
       "      <td>0.744845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic regression with balanced class weights</th>\n",
       "      <td>0.685694</td>\n",
       "      <td>0.661209</td>\n",
       "      <td>0.484808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Accuracy  Balanced accuracy  \\\n",
       "Dummy classifier                                 0.931483           0.500000   \n",
       "Logistic regression                              0.931483           0.500000   \n",
       "Random forest                                    0.947269           0.597826   \n",
       "Logistic regression with balanced class weights  0.685694           0.661209   \n",
       "\n",
       "                                                 f1_score  \n",
       "Dummy classifier                                 0.492308  \n",
       "Logistic regression                              0.492308  \n",
       "Random forest                                    0.744845  \n",
       "Logistic regression with balanced class weights  0.484808  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy classifier vs LogisticRegression vs Random forest vs Logistic regression with balanced class weights\n",
    "lr_clf.set_params(class_weight=\"balanced\")\n",
    "\n",
    "index += [\"Logistic regression with balanced class weights\"]\n",
    "cv_result = cross_validate(lr_clf,  X_new, y, scoring=scoring)\n",
    "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
    "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
    "\n",
    "scores[\"f1_score\"].append(f1_score(lr_clf.fit(xtrain, ytrain).predict(xtest), ytest,average='macro'))\n",
    "\n",
    "df_scores = pd.DataFrame(scores, index=index)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy classifier</th>\n",
       "      <td>0.931483</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.492308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic regression</th>\n",
       "      <td>0.931483</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.492308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.947269</td>\n",
       "      <td>0.597826</td>\n",
       "      <td>0.744845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic regression with balanced class weights</th>\n",
       "      <td>0.685694</td>\n",
       "      <td>0.661209</td>\n",
       "      <td>0.484808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest with balanced class weights</th>\n",
       "      <td>0.947269</td>\n",
       "      <td>0.582246</td>\n",
       "      <td>0.492308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Accuracy  Balanced accuracy  \\\n",
       "Dummy classifier                                 0.931483           0.500000   \n",
       "Logistic regression                              0.931483           0.500000   \n",
       "Random forest                                    0.947269           0.597826   \n",
       "Logistic regression with balanced class weights  0.685694           0.661209   \n",
       "Random forest with balanced class weights        0.947269           0.582246   \n",
       "\n",
       "                                                 f1_score  \n",
       "Dummy classifier                                 0.492308  \n",
       "Logistic regression                              0.492308  \n",
       "Random forest                                    0.744845  \n",
       "Logistic regression with balanced class weights  0.484808  \n",
       "Random forest with balanced class weights        0.492308  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy classifier vs LogisticRegression vs Random forest vs Logistic regression with balanced class weights vs Random forest with balanced class weights\n",
    "rf_clf.set_params(class_weight=\"balanced\")\n",
    "\n",
    "index += [\"Random forest with balanced class weights\"]\n",
    "cv_result = cross_validate(rf_clf, X_new, y, scoring=scoring)\n",
    "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
    "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
    "\n",
    "scores[\"f1_score\"].append(f1_score(rf_clf.fit(xtrain, ytrain).predict(xtest), ytest,average='macro'))\n",
    "\n",
    "df_scores = pd.DataFrame(scores, index=index)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy classifier</th>\n",
       "      <td>0.931483</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.492308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic regression</th>\n",
       "      <td>0.931483</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.492308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.947269</td>\n",
       "      <td>0.597826</td>\n",
       "      <td>0.744845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic regression with balanced class weights</th>\n",
       "      <td>0.685694</td>\n",
       "      <td>0.661209</td>\n",
       "      <td>0.484808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest with balanced class weights</th>\n",
       "      <td>0.947269</td>\n",
       "      <td>0.582246</td>\n",
       "      <td>0.492308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Under-sampling + Logistic regression</th>\n",
       "      <td>0.640981</td>\n",
       "      <td>0.652980</td>\n",
       "      <td>0.422500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Accuracy  Balanced accuracy  \\\n",
       "Dummy classifier                                 0.931483           0.500000   \n",
       "Logistic regression                              0.931483           0.500000   \n",
       "Random forest                                    0.947269           0.597826   \n",
       "Logistic regression with balanced class weights  0.685694           0.661209   \n",
       "Random forest with balanced class weights        0.947269           0.582246   \n",
       "Under-sampling + Logistic regression             0.640981           0.652980   \n",
       "\n",
       "                                                 f1_score  \n",
       "Dummy classifier                                 0.492308  \n",
       "Logistic regression                              0.492308  \n",
       "Random forest                                    0.744845  \n",
       "Logistic regression with balanced class weights  0.484808  \n",
       "Random forest with balanced class weights        0.492308  \n",
       "Under-sampling + Logistic regression             0.422500  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy classifier vs LogisticRegression vs Random forest vs Logistic regression with balanced class weights vs Random forest with balanced class weights vs Under-sampling + Logistic regression\n",
    "\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_with_sampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "lr_clf = make_pipeline_with_sampler(\n",
    "    RandomUnderSampler(random_state=42),\n",
    "    LogisticRegression(max_iter=1000, class_weight=\"balance\"),\n",
    ")\n",
    "index += [\"Under-sampling + Logistic regression\"]\n",
    "cv_result = cross_validate(lr_clf, X_new, y, scoring=scoring)\n",
    "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
    "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
    "\n",
    "scores[\"f1_score\"].append(f1_score(lr_clf.fit(xtrain, ytrain).predict(xtest), ytest,average='macro'))\n",
    "\n",
    "df_scores = pd.DataFrame(scores, index=index)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy classifier</th>\n",
       "      <td>0.931483</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.492308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic regression</th>\n",
       "      <td>0.931483</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.492308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.947269</td>\n",
       "      <td>0.597826</td>\n",
       "      <td>0.744845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic regression with balanced class weights</th>\n",
       "      <td>0.685694</td>\n",
       "      <td>0.661209</td>\n",
       "      <td>0.484808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest with balanced class weights</th>\n",
       "      <td>0.947269</td>\n",
       "      <td>0.582246</td>\n",
       "      <td>0.492308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Under-sampling + Logistic regression</th>\n",
       "      <td>0.640981</td>\n",
       "      <td>0.652980</td>\n",
       "      <td>0.422500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced random forest</th>\n",
       "      <td>0.647289</td>\n",
       "      <td>0.671961</td>\n",
       "      <td>0.422840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Accuracy  Balanced accuracy  \\\n",
       "Dummy classifier                                 0.931483           0.500000   \n",
       "Logistic regression                              0.931483           0.500000   \n",
       "Random forest                                    0.947269           0.597826   \n",
       "Logistic regression with balanced class weights  0.685694           0.661209   \n",
       "Random forest with balanced class weights        0.947269           0.582246   \n",
       "Under-sampling + Logistic regression             0.640981           0.652980   \n",
       "Balanced random forest                           0.647289           0.671961   \n",
       "\n",
       "                                                 f1_score  \n",
       "Dummy classifier                                 0.492308  \n",
       "Logistic regression                              0.492308  \n",
       "Random forest                                    0.744845  \n",
       "Logistic regression with balanced class weights  0.484808  \n",
       "Random forest with balanced class weights        0.492308  \n",
       "Under-sampling + Logistic regression             0.422500  \n",
       "Balanced random forest                           0.422840  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy classifier vs LogisticRegression vs Random forest vs Logistic regression with balanced class weights vs Random forest with balanced class weights vs Under-sampling + Logistic regression vs Balanced random forest\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "rf_clf = BalancedRandomForestClassifier(random_state=42, n_jobs=2)\n",
    "index += [\"Balanced random forest\"]\n",
    "cv_result = cross_validate(rf_clf, X_new, y, scoring=scoring)\n",
    "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
    "scores[\"Balanced accuracy\"].append(cv_result[\"test_balanced_accuracy\"].mean())\n",
    "\n",
    "scores[\"f1_score\"].append(f1_score(rf_clf.fit(xtrain, ytrain).predict(xtest), ytest,average='macro'))\n",
    "\n",
    "df_scores = pd.DataFrame(scores, index=index)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
