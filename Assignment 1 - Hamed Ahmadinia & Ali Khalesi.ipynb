{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment1\n",
    "\n",
    "Remember -> submission using itslearning, both notebook and github repo *deadline on 22.11.2021*\n",
    "\n",
    "#### Task 1 (3 points):\n",
    "\n",
    "Regression $\\to$ Superconductivity Data Set\n",
    "\n",
    "The goal here is to predict the critical temperature based on the features extracted.\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Superconductivty+Data\n",
    "\n",
    "* Fit two regression models to predict the critical temperature. Report the score with the default parameters of each model.\n",
    "* Perform a simple manual optimization for one of the default parameters (at least 5 different values) and plot the new obtained score as a function of the chosen parameter. Plot the coefficient magnitudes for the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up required environment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_rows = 3000\n",
    "pd.set_option('display.width', 1200)\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_elements</th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>wtd_gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>std_atomic_mass</th>\n",
       "      <th>...</th>\n",
       "      <th>wtd_mean_Valence</th>\n",
       "      <th>gmean_Valence</th>\n",
       "      <th>wtd_gmean_Valence</th>\n",
       "      <th>entropy_Valence</th>\n",
       "      <th>wtd_entropy_Valence</th>\n",
       "      <th>range_Valence</th>\n",
       "      <th>wtd_range_Valence</th>\n",
       "      <th>std_Valence</th>\n",
       "      <th>wtd_std_Valence</th>\n",
       "      <th>critical_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.862692</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.116612</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.062396</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>31.794921</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.219783</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.066221</td>\n",
       "      <td>1</td>\n",
       "      <td>1.085714</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.437059</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>92.729214</td>\n",
       "      <td>58.518416</td>\n",
       "      <td>73.132787</td>\n",
       "      <td>36.396602</td>\n",
       "      <td>1.449309</td>\n",
       "      <td>1.057755</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>36.161939</td>\n",
       "      <td>47.094633</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>1.888175</td>\n",
       "      <td>2.210679</td>\n",
       "      <td>1.557113</td>\n",
       "      <td>1.047221</td>\n",
       "      <td>2</td>\n",
       "      <td>1.128571</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.468606</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.885242</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.122509</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>0.975980</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>35.741099</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.271429</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.232679</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.029175</td>\n",
       "      <td>1</td>\n",
       "      <td>1.114286</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.444697</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.873967</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.119560</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.022291</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>33.768010</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.264286</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.226222</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.048834</td>\n",
       "      <td>1</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.440952</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.840143</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.110716</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.129224</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>27.848743</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.242857</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.206963</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.096052</td>\n",
       "      <td>1</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.428809</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass  gmean_atomic_mass  wtd_gmean_atomic_mass  entropy_atomic_mass  wtd_entropy_atomic_mass  range_atomic_mass  wtd_range_atomic_mass  std_atomic_mass  ...  wtd_mean_Valence  gmean_Valence  wtd_gmean_Valence  entropy_Valence  wtd_entropy_Valence  range_Valence  wtd_range_Valence  std_Valence  wtd_std_Valence  critical_temp\n",
       "0                   4         88.944468             57.862692          66.361592              36.116612             1.181795                 1.062396          122.90607              31.794921        51.968828  ...          2.257143       2.213364           2.219783         1.368922             1.066221              1           1.085714     0.433013         0.437059           29.0\n",
       "1                   5         92.729214             58.518416          73.132787              36.396602             1.449309                 1.057755          122.90607              36.161939        47.094633  ...          2.257143       1.888175           2.210679         1.557113             1.047221              2           1.128571     0.632456         0.468606           26.0\n",
       "2                   4         88.944468             57.885242          66.361592              36.122509             1.181795                 0.975980          122.90607              35.741099        51.968828  ...          2.271429       2.213364           2.232679         1.368922             1.029175              1           1.114286     0.433013         0.444697           19.0\n",
       "3                   4         88.944468             57.873967          66.361592              36.119560             1.181795                 1.022291          122.90607              33.768010        51.968828  ...          2.264286       2.213364           2.226222         1.368922             1.048834              1           1.100000     0.433013         0.440952           22.0\n",
       "4                   4         88.944468             57.840143          66.361592              36.110716             1.181795                 1.129224          122.90607              27.848743        51.968828  ...          2.242857       2.213364           2.206963         1.368922             1.096052              1           1.057143     0.433013         0.428809           23.0\n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading dataset from provided link and showing the first 5 rows \n",
    "\n",
    "import zipfile, requests, io\n",
    "URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00464/superconduct.zip'\n",
    "file_name = 'train.csv'\n",
    "data = pd.read_csv(zipfile.ZipFile(io.BytesIO(requests.get(URL, stream=True).content)).open(file_name))\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing 3 different regression models from sklearn\n",
    "# linear regresion = a linear approach for modelling the relationship between a scalar response and one or more explanatory variables \n",
    "# Ridge = a model tuning method that is used to analyse any data that suffers from multicollinearity.\n",
    "# Lasso = a type of linear regression that uses shrinkage. Shrinkage is where data values are shrunk towards a central point, like the mean.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "linear = LinearRegression()\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making traning set by spliting data while we want to predict the critical temperature \"critical_temp\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('critical_temp', axis=1), data[['critical_temp']], test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1843274.139761019, tolerance: 1997.1995514368925\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lasso()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fiting data from Superconductivity Data Set into three regression models including Linearregression, ridge, and lasso\n",
    "linear.fit(X_train, y_train)\n",
    "ridge.fit(X_train, y_train)\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse linear regression:  17.577418357906904\n",
      "rmse ridge regression:  17.597462281417922\n",
      "rmse lasso regression:  18.42387590058169\n"
     ]
    }
   ],
   "source": [
    "# calculating mean squired eroor for all three regression models including Linearregression, ridge, and lasso\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print('rmse linear regression: ', np.sqrt(mean_squared_error(y_test, linear.predict(X_test))))\n",
    "print('rmse ridge regression: ', np.sqrt(mean_squared_error(y_test, ridge.predict(X_test))))\n",
    "print('rmse lasso regression: ', np.sqrt(mean_squared_error(y_test, lasso.predict(X_test))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2659158.8383040144, tolerance: 1997.1995514368925\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2670471.311969319, tolerance: 1997.1995514368925\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2678534.7936570677, tolerance: 1997.1995514368925\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2686244.964927356, tolerance: 1997.1995514368925\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2692489.392401426, tolerance: 1997.1995514368925\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2697656.033974792, tolerance: 1997.1995514368925\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2701779.170666342, tolerance: 1997.1995514368925\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2704631.830877468, tolerance: 1997.1995514368925\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2690162.320086359, tolerance: 1997.1995514368925\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2514b38c640>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the new obtained score\n",
    "\n",
    "alpha = np.arange(.002, .02, .002)\n",
    "rmse = []\n",
    "\n",
    "for a in alpha:\n",
    "    rmse.append(np.sqrt(mean_squared_error(y_test, Lasso(alpha=a).fit(X_train, y_train).predict(X_test))))\n",
    "    \n",
    "plt.figure(figsize=(20,9))\n",
    "plt.scatter(alpha, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2147416.18676842, tolerance: 1587.1683843732255\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2117868.5499325204, tolerance: 1604.6020807718128\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2149647.7966823652, tolerance: 1603.7168053746134\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2128143.326122776, tolerance: 1583.7587117726143\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2143123.4795712614, tolerance: 1609.4635113704333\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2161522.884461552, tolerance: 1587.1683843732255\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2131822.8009110615, tolerance: 1604.6020807718128\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2165194.7684001285, tolerance: 1603.7168053746134\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2143177.009250511, tolerance: 1583.7587117726143\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2157589.376418275, tolerance: 1609.4635113704333\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2173250.1315796445, tolerance: 1587.1683843732255\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2141908.076536179, tolerance: 1604.6020807718128\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2173783.0748358513, tolerance: 1603.7168053746134\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2156354.4109088555, tolerance: 1583.7587117726143\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2171502.824096932, tolerance: 1609.4635113704333\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2181317.092267314, tolerance: 1587.1683843732255\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2155142.8863084484, tolerance: 1604.6020807718128\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2186679.449096054, tolerance: 1603.7168053746134\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2169039.9447249863, tolerance: 1583.7587117726143\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2179503.738040343, tolerance: 1609.4635113704333\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2192350.5115450574, tolerance: 1587.1683843732255\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2166941.3468704913, tolerance: 1604.6020807718128\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2197602.9796011215, tolerance: 1603.7168053746134\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2183255.9374312004, tolerance: 1583.7587117726143\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2190318.732947961, tolerance: 1609.4635113704333\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bet Parameter =  {'alpha': 0.005}\n",
      "Best Estimator =  Lasso(alpha=0.005)\n",
      "Best Score =  0.7320606597042277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2673715.7771729245, tolerance: 1997.1995514368925\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# simple manual optimization for lasso parameters (at least 5 different values)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lasso_parameter = {'alpha':[0.005, .01, 0.02, 0.03, 0.05]}\n",
    "grid_search = GridSearchCV(Lasso(), param_grid=lasso_parameter, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Bet Parameter = \",grid_search.best_params_)\n",
    "print(\"Best Estimator = \", grid_search.best_estimator_)\n",
    "print(\"Best Score = \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse best lasso regression:  17.683823983140613\n"
     ]
    }
   ],
   "source": [
    "print('rmse best lasso regression: ', np.sqrt(mean_squared_error(y_test, grid_search.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 (3 points):\n",
    "\n",
    "Binary classification $\\to$ Default of credit card clients Data Set\n",
    "\n",
    "The goal here is to predict the default payment next month.\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients\n",
    "\n",
    "* Fit two binary classification models to predict the client's credit card default. Report accuracy with the default parameters of each model.\n",
    "* Perform a simple manual optimization for one of the default parameters (at least 5 different values) and plot the new obtained accuracy as a function of the chosen parameter.. Plot the feature importance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month\n",
       "0   1      20000    2          2         1   24      2      2     -1     -1  ...          0          0          0         0       689         0         0         0         0                           1\n",
       "1   2     120000    2          2         2   26     -1      2      0      0  ...       3272       3455       3261         0      1000      1000      1000         0      2000                           1\n",
       "2   3      90000    2          2         2   34      0      0      0      0  ...      14331      14948      15549      1518      1500      1000      1000      1000      5000                           0\n",
       "3   4      50000    2          2         1   37      0      0      0      0  ...      28314      28959      29547      2000      2019      1200      1100      1069      1000                           0\n",
       "4   5      50000    1          2         1   57     -1      0     -1      0  ...      20940      19146      19131      2000     36681     10000      9000       689       679                           0\n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading creditcards dataset and checking the heading for the first 5 raws\n",
    "\n",
    "URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls'\n",
    "data = pd.read_excel(URL, header=1)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 25)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking data shape\n",
    "data = data.set_index(data.ID)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'default payment next month'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking data colomns\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making traning set by spliting data while we want to predict \"default payment next month\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('default payment next month', axis=1), data[['default payment next month']], test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "<ipython-input-15-421c293c9a3b>:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  forest.fit(X_train, y_train)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit two binary classification modelsincluding Random Forest Classifier and MLPClassifier to predict the client's credit card default\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "logistic = LogisticRegression()\n",
    "forest = RandomForestClassifier()\n",
    "nn = MLPClassifier()\n",
    "\n",
    "logistic.fit(X_train, y_train)\n",
    "forest.fit(X_train, y_train)\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      4648\n",
      "           1       0.66      0.36      0.47      1352\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.75      0.65      0.68      6000\n",
      "weighted avg       0.80      0.81      0.79      6000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      4648\n",
      "           1       0.00      0.00      0.00      1352\n",
      "\n",
      "    accuracy                           0.77      6000\n",
      "   macro avg       0.39      0.50      0.44      6000\n",
      "weighted avg       0.60      0.77      0.68      6000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      4648\n",
      "           1       0.40      0.46      0.43      1352\n",
      "\n",
      "    accuracy                           0.72      6000\n",
      "   macro avg       0.62      0.63      0.62      6000\n",
      "weighted avg       0.74      0.72      0.73      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking classification report \n",
    "# Report accuracy with the default parameters of each model\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, forest.predict(X_test)))\n",
    "\n",
    "print(classification_report(y_test, logistic.predict(X_test)))\n",
    "\n",
    "print(classification_report(y_test, nn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2514bcdd550>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIcAAAIICAYAAAD0R46sAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAdsElEQVR4nO3dYaye513f8d9/dsKcwEhRXFicQMKUZqNAGzgLsApo6UrCBCQgJgW2gbZpURBlo9qyJUNi2isQmTahqayKICsvoBGDJM0LiFOh0SJES06alCQNBiuUxDZbXKrA6DzShP9enMft6ck58ePazuOe/+cjWec8133dz7mOcsV+/PVz36e6OwAAAADM9NdWvQAAAAAAVkccAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYbO+qF7CdSy+9tK+88spVLwMAAABg13jkkUc+3t37t46fl3HoyiuvzPr6+qqXAQAAALBrVNUfbzfusjIAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMH2rnoBu9H9jx7NnQcP5djzJ3LZJfty2/XX5KZrD6x6WQAAAAAvIw6dZfc/ejR33Pt4TnzqpSTJ0edP5I57H08SgQgAAAA477is7Cy78+ChT4ehk0586qXcefDQilYEAAAAsDNx6Cw79vyJ0xoHAAAAWCVx6Cy77JJ9pzUOAAAAsEri0Fl22/XXZN8Fez5rbN8Fe3Lb9desaEUAAAAAO3ND6rPs5E2n/bQyAAAA4POBOHQO3HTtATEIAAAAPo/d/+jRMW/8EIcAAAAANrn/0aO5497HP/3TyI8+fyJ33Pt4kuzKQOSeQwAAAACb3Hnw0KfD0EknPvVS7jx4aEUrOrfEIQAAAIBNjj1/4rTGP9+5rAwAAHahSffKADjbLrtkX45uE4Iuu2TfClZz7nnnEAAA7DIn75Vx9PkT6XzmXhn3P3p01UsD+Lxw2/XXZN8Fez5rbN8Fe3Lb9desaEXnljgEAAC7zLR7ZQCcbTddeyA/+b1fkwOX7EslOXDJvvzk937Nrn0HpsvKAABgl5l2rwyAc+Gmaw/s2hi0lXcOAQDALrPTPTF2670yADgz4hAAAOwy0+6VAcCZcVkZAADsMicvg/DTygBYhjgEAAC70KR7ZQBwZlxWBgAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADDYUnGoqm6oqkNVdbiqbt/m+G1V9dji1xNV9VJVfcni2Meq6vHFsfWz/Q0AAAAA8Lnbe6oJVbUnyTuTvC3JkSQPV9UD3f3Rk3O6+84kdy7mf1eSd3T3JzY9zVu6++NndeUAAAAAnLFl3jl0XZLD3f10d7+Q5J4kN77C/O9P8p6zsTgAAAAAzq1l4tCBJM9uenxkMfYyVXVRkhuS/Oqm4U7yUFU9UlW37PRFquqWqlqvqvXjx48vsSwAAAAAztQycai2Gesd5n5Xkt/ecknZm7r765J8R5Ifqapv2e7E7r6ru9e6e23//v1LLAsAAACAM7VMHDqS5IpNjy9PcmyHuTdnyyVl3X1s8fG5JPdl4zI1AAAAAM4Dy8Shh5NcXVVXVdWF2QhAD2ydVFVfnORbk7x309jFVfVFJz9P8u1JnjgbCwcAAADgzJ3yp5V194tV9fYkB5PsSXJ3dz9ZVbcujr9rMfV7kjzU3Z/cdPqXJrmvqk5+rV/q7gfP5jcAAAAAwOeuune6fdDqrK2t9fr6+qqXAQAAALBrVNUj3b22dXyZy8oAAAAA2KXEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwZaKQ1V1Q1UdqqrDVXX7Nsdvq6rHFr+eqKqXqupLljkXAAAAgNU5ZRyqqj1J3pnkO5J8VZLvr6qv2jynu+/s7jd29xuT3JHk/d39iWXOBQAAAGB1lnnn0HVJDnf30939QpJ7ktz4CvO/P8l7PsdzAQAAAHgVLROHDiR5dtPjI4uxl6mqi5LckORXT/dcAAAAAF59y8Sh2masd5j7XUl+u7s/cbrnVtUtVbVeVevHjx9fYlkAAAAAnKll4tCRJFdsenx5kmM7zL05n7mk7LTO7e67unutu9f279+/xLIAAAAAOFPLxKGHk1xdVVdV1YXZCEAPbJ1UVV+c5FuTvPd0zwUAAABgNfaeakJ3v1hVb09yMMmeJHd395NVdevi+LsWU78nyUPd/clTnXu2vwkAAAAAPjfVvdPtg1ZnbW2t19fXV70MAAAAgF2jqh7p7rWt48tcVgYAAADALiUOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADCYOAQAAAAwmDgEAAAAMJg4BAAAADLZUHKqqG6rqUFUdrqrbd5jz5qp6rKqerKr3bxr/WFU9vji2frYWDgAAAMCZ23uqCVW1J8k7k7wtyZEkD1fVA9390U1zLknys0lu6O5nquq1W57mLd398bO3bAAAAADOhmXeOXRdksPd/XR3v5DkniQ3bpnzA0nu7e5nkqS7nzu7ywQAAADgXFgmDh1I8uymx0cWY5u9Lslrquo3q+qRqvrBTcc6yUOL8Vt2+iJVdUtVrVfV+vHjx5ddPwAAAABn4JSXlSWpbcZ6m+f5+iRvTbIvye9U1Qe7+w+SvKm7jy0uNXtfVf1+d3/gZU/YfVeSu5JkbW1t6/MDAAAAcA4s886hI0mu2PT48iTHtpnzYHd/cnFvoQ8keUOSdPexxcfnktyXjcvUAAAAADgPLBOHHk5ydVVdVVUXJrk5yQNb5rw3yTdX1d6quijJNyR5qqourqovSpKqujjJtyd54uwtHwAAAIAzccrLyrr7xap6e5KDSfYkubu7n6yqWxfH39XdT1XVg0l+L8lfJfm57n6iqr4yyX1VdfJr/VJ3P3iuvhkAAAAATk91n3+391lbW+v19fVVLwMAAABg16iqR7p7bev4MpeVAQAAALBLiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIOJQwAAAACDiUMAAAAAg4lDAAAAAIMtFYeq6oaqOlRVh6vq9h3mvLmqHquqJ6vq/adzLgAAAACrsfdUE6pqT5J3JnlbkiNJHq6qB7r7o5vmXJLkZ5Pc0N3PVNVrlz0XAAAAgNVZ5p1D1yU53N1Pd/cLSe5JcuOWOT+Q5N7ufiZJuvu50zgXAAAAgBVZJg4dSPLspsdHFmObvS7Ja6rqN6vqkar6wdM4FwAAAIAVOeVlZUlqm7He5nm+Pslbk+xL8jtV9cElz934IlW3JLklSb78y798iWUBAAAAcKaWeefQkSRXbHp8eZJj28x5sLs/2d0fT/KBJG9Y8twkSXff1d1r3b22f//+ZdcPAAAAwBlYJg49nOTqqrqqqi5McnOSB7bMeW+Sb66qvVV1UZJvSPLUkucCAAAAsCKnvKysu1+sqrcnOZhkT5K7u/vJqrp1cfxd3f1UVT2Y5PeS/FWSn+vuJ5Jku3PP0fcCAAAAwGmq7m1vAbRSa2trvb6+vuplAAAAAOwaVfVId69tHV/msjIAAAAAdilxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYLCl4lBV3VBVh6rqcFXdvs3xN1fVn1XVY4tfP7Hp2Meq6vHF+PrZXDwAAAAAZ2bvqSZU1Z4k70zytiRHkjxcVQ9090e3TP2t7v7OHZ7mLd398TNbKgAAAABn2zLvHLouyeHufrq7X0hyT5Ibz+2yAAAAAHg1LBOHDiR5dtPjI4uxrb6pqj5SVb9eVa/fNN5JHqqqR6rqlp2+SFXdUlXrVbV+/PjxpRYPAAAAwJk55WVlSWqbsd7y+MNJvqK7/6Kq/kGS+5NcvTj2pu4+VlWvTfK+qvr97v7Ay56w+64kdyXJ2tra1ucHAAAA4BxY5p1DR5Jcsenx5UmObZ7Q3X/e3X+x+PzXklxQVZcuHh9bfHwuyX3ZuEwNAAAAgPPAMnHo4SRXV9VVVXVhkpuTPLB5QlV9WVXV4vPrFs/7p1V1cVV90WL84iTfnuSJs/kNAAAAAPC5O+VlZd39YlW9PcnBJHuS3N3dT1bVrYvj70ryfUl+uKpeTHIiyc3d3VX1pUnuW3SjvUl+qbsfPEffCwAAAACnqbrPv9v7rK2t9fr6+qqXAQAAALBrVNUj3b22dXyZy8oAAAAA2KXEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMHEIQAAAIDBxCEAAACAwcQhAAAAgMGWikNVdUNVHaqqw1V1+zbH31xVf1ZVjy1+/cSy5wIAAACwOntPNaGq9iR5Z5K3JTmS5OGqeqC7P7pl6m9193d+jucCAAAAsALLvHPouiSHu/vp7n4hyT1Jblzy+c/kXAAAAADOsWXi0IEkz256fGQxttU3VdVHqurXq+r1p3luquqWqlqvqvXjx48vsSwAAAAAztQycai2Gestjz+c5Cu6+w1J/muS+0/j3I3B7ru6e6271/bv37/EsgAAAAA4U8vEoSNJrtj0+PIkxzZP6O4/7+6/WHz+a0kuqKpLlzkXAAAAgNVZJg49nOTqqrqqqi5McnOSBzZPqKovq6pafH7d4nn/dJlzAQAAAFidU/60su5+sarenuRgkj1J7u7uJ6vq1sXxdyX5viQ/XFUvJjmR5Obu7iTbnnuOvhcAAAAATlNtNJzzy9raWq+vr696GQAAAAC7RlU90t1rW8eXuawMAAAAgF1KHAIAAAAY7JT3HAKAV9v9jx7NnQcP5djzJ3LZJfty2/XX5KZrD6x6WQAAsCuJQwCcV+5/9GjuuPfxnPjUS0mSo8+fyB33Pp4kAhEAAJwDLisD4Lxy58FDnw5DJ5341Eu58+ChFa0IAAB2N3EIgPPKsedPnNY4AABwZsQhAM4rl12y77TGAQCAMyMOAXBeue36a7Lvgj2fNbbvgj257fprVrQiAADY3dyQGoDzysmbTvtpZQAA8OoQhwA479x07QExCAAAXiUuKwMAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGEwcAgAAABhMHAIAAAAYTBwCAAAAGKy6e9VreJmqOp7kj1e9Ds66S5N8fNWL4Lxkb7ATe4NXYn+wE3uDndgbvBL7g53spr3xFd29f+vgeRmH2J2qar2711a9Ds4/9gY7sTd4JfYHO7E32Im9wSuxP9jJhL3hsjIAAACAwcQhAAAAgMHEIV5Nd616AZy37A12Ym/wSuwPdmJvsBN7g1dif7CTXb833HMIAAAAYDDvHAIAAAAYTBzinKiqS6rqV6rq96vqqar6pqr6kqp6X1X94eLja1a9Tl59VfWOqnqyqp6oqvdU1V+3N+aqqrur6rmqemLT2I77oaruqKrDVXWoqq5fzap5NeywN+5c/Lnye1V1X1VdsumYvTHIdvtj07F/U1VdVZduGrM/hthpb1TVjy7++z9ZVT+9adzeGGKHP1feWFUfrKrHqmq9qq7bdMzeGKKqrqiq/7n4e+uTVfWvFuOjXpOKQ5wrP5Pkwe7+20nekOSpJLcn+Y3uvjrJbyweM0hVHUjyL5OsdfdXJ9mT5ObYG5O9O8kNW8a23Q9V9VXZ2C+vX5zzs1W159VbKq+yd+fle+N9Sb66u782yR8kuSOxN4Z6d16+P1JVVyR5W5JnNo3ZH7O8O1v2RlW9JcmNSb62u1+f5D8txu2NWd6dl/++8dNJ/mN3vzHJTywe2xvzvJjkX3f330nyjUl+ZLEHRr0mFYc466rqbyT5liQ/nyTd/UJ3P5+NP5R/YTHtF5LctIr1sXJ7k+yrqr1JLkpyLPbGWN39gSSf2DK80364Mck93f2X3f1HSQ4nuS7sStvtje5+qLtfXDz8YJLLF5/bG8Ps8HtHkvyXJP82yeabatofg+ywN344yU91918u5jy3GLc3Btlhb3SSv7H4/Iuz8bo0sTdG6e4/6e4PLz7/P9l4Y8OBDHtNKg5xLnxlkuNJ/ntVPVpVP1dVFyf50u7+k2Tjf8Akr13lInn1dffRbPxr3TNJ/iTJn3X3Q7E3+Gw77YcDSZ7dNO/IYoyZ/lmSX198bm+QqvruJEe7+yNbDtkfvC7JN1fVh6rq/VX1dxfj9gY/luTOqno2G69R71iM2xtDVdWVSa5N8qEMe00qDnEu7E3ydUn+W3dfm+STcZkQSRbX6d6Y5KoklyW5uKr+8WpXxeeR2mbMj9wcqKp+PBtvAf/Fk0PbTLM3Bqmqi5L8eDYuC3nZ4W3G7I9Z9iZ5TTYuF7ktyS9XVcXeYONdZe/o7iuSvCOLKx9ib4xUVV+Y5FeT/Fh3//krTd1m7PN+f4hDnAtHkhzp7g8tHv9KNmLR/66qv5kki4/P7XA+u9ffT/JH3X28uz+V5N4kfy/2Bp9tp/1wJMkVm+Zdns+8/ZshquqHknxnkn/U3SdfiNkb/K1s/MPDR6rqY9nYAx+uqi+L/cHGHri3N/xukr9KcmnsDZIfysbr0ST5H/nMpUH2xjBVdUE2wtAvdvfJPTHqNak4xFnX3f8rybNVdc1i6K1JPprkgWz8BpzFx/euYHms1jNJvrGqLlr8i91bs3FNr73BZjvthweS3FxVX1BVVyW5OsnvrmB9rEhV3ZDk3yX57u7+v5sO2RvDdffj3f3a7r6yu6/Mxgv3r1u8JrE/uD/JtyVJVb0uyYVJPh57g42/0H/r4vNvS/KHi8/tjUEWfy/5+SRPdfd/3nRo1GvSvateALvWjyb5xaq6MMnTSf5pNmLkL1fVP89GJPiHK1wfK9DdH6qqX0ny4WxcEvJokruSfGHsjZGq6j1J3pzk0qo6kuQ/JPmpbLMfuvvJqvrlbMTmF5P8SHe/tJKFc87tsDfuSPIFSd638TouH+zuW+2NebbbH93989vNtT9m2eH3jruT3L34EeYvJPmhxTsP7Y1Bdtgb/yLJzyx+UMr/S3JL4veNgd6U5J8kebyqHluM/fsMe01an3lHNgAAAADTuKwMAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGAwcQgAAABgMHEIAAAAYDBxCAAAAGCw/w9gHYHjY5zhhAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform a simple manual optimization for one of the default parameters \n",
    "# plot the new obtained accuracy as a function of the chosen parameter.. Plot the feature importance\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "hidden_layer_sizes = np.arange(50,250, 50)\n",
    "accuracy = []\n",
    "\n",
    "for layer in hidden_layer_sizes:\n",
    "    accuracy.append(accuracy_score(y_test, MLPClassifier(hidden_layer_sizes=(layer, ),\n",
    "              activation='relu', solver='adam', \n",
    "             alpha=0.0001, batch_size='auto',\n",
    "            learning_rate='constant', learning_rate_init=0.001, power_t=0.5, \n",
    "             max_iter=1000, shuffle=True, random_state=None, tol=0.0001,\n",
    "            verbose=False, warm_start=False, momentum=0.9, \n",
    "             nesterovs_momentum=True, early_stopping=False,\n",
    "            validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, \n",
    "             n_iter_no_change=10).fit(X_train, y_train).predict(X_test)))\n",
    "    \n",
    "plt.figure(figsize=(20,9))\n",
    "plt.scatter(hidden_layer_sizes, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3 (9 points): \n",
    "\n",
    "Multiclass & binary classification $\\to$ Drug consumption (quantified) Data Set\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Drug+consumption+%28quantified%29\n",
    "\n",
    "Data Set Information:\n",
    "\n",
    "Database contains records for 1885 respondents. For each respondent 12 attributes are known: Personality measurements which include NEO-FFI-R (neuroticism, extraversion, openness to experience, agreeableness, and conscientiousness), BIS-11 (impulsivity), and ImpSS (sensation seeking), level of education, age, gender, country of residence and ethnicity. All input attributes are originally categorical and are quantified. After quantification values of all input features can be considered as real-valued. In addition, participants were questioned concerning their use of 18 legal and illegal drugs (alcohol, amphetamines, amyl nitrite, benzodiazepine, cannabis, chocolate, cocaine, caffeine, crack, ecstasy, heroin, ketamine, legal highs, LSD, methadone, mushrooms, nicotine and volatile substance abuse and one fictitious drug (Semeron) which was introduced to identify over-claimers. For each drug they have to select one of the answers: never used the drug, used it over a decade ago, or in the last decade, year, month, week, or day.\n",
    "\n",
    "Database contains 18 classification problems. Each of independent label variables contains seven classes: \"Never Used\", \"Used over a Decade Ago\", \"Used in Last Decade\", \"Used in Last Year\", \"Used in Last Month\", \"Used in Last Week\", and \"Used in Last Day\".\n",
    "\n",
    "* Fit two multiclass classification models to predict two selected features out of 18. Use numerical values to represent each class. Report accuracy with the default parameters of each model.\n",
    "* Perform a simple manual optimization for one of the default parameters (at least 5 different values) for one of the previous models. Plot the new obtained accuracy as a function of the chosen parameter. \n",
    "* Fit one multiclass classification model for all the rest 16 features. Comment on the accuracy of predicting each feature, for all the seven classes. \n",
    "* Run one binary classification model for 3 features out of 18. Test the performance of the model by choosing as:\n",
    " - one class (class 0) the variable \"Used in Last Decade\" and the remaining variables for the other class (class 1).\n",
    " - one class (class 0) the variables \"Used in Last Decade\" and \"Used in Last Year\" and the remaining variables for the other class (class 1).\n",
    " - one class (class 0) the variables \"Used in Last Decade\", \"Used in Last Year\", \"Used in Last Month\" and the remaining variables for the other class (class 1).\n",
    " \n",
    " Comment your results, and point which selection of classes have better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v0</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v22</th>\n",
       "      <th>v23</th>\n",
       "      <th>v24</th>\n",
       "      <th>v25</th>\n",
       "      <th>v26</th>\n",
       "      <th>v27</th>\n",
       "      <th>v28</th>\n",
       "      <th>v29</th>\n",
       "      <th>v30</th>\n",
       "      <th>v31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>...</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>...</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   v0       v1       v2       v3       v4       v5       v6       v7       v8       v9  ...  v22  v23  v24  v25  v26  v27  v28  v29  v30  v31\n",
       "0   1  0.49788  0.48246 -0.05921  0.96082  0.12600  0.31287 -0.57545 -0.58331 -0.91699  ...  CL0  CL0  CL0  CL0  CL0  CL0  CL0  CL2  CL0  CL0\n",
       "1   2 -0.07854 -0.48246  1.98437  0.96082 -0.31685 -0.67825  1.93886  1.43533  0.76096  ...  CL4  CL0  CL2  CL0  CL2  CL3  CL0  CL4  CL0  CL0\n",
       "2   3  0.49788 -0.48246 -0.05921  0.96082 -0.31685 -0.46725  0.80523 -0.84732 -1.62090  ...  CL0  CL0  CL0  CL0  CL0  CL0  CL1  CL0  CL0  CL0\n",
       "3   4 -0.95197  0.48246  1.16365  0.96082 -0.31685 -0.14882 -0.80615 -0.01928  0.59042  ...  CL0  CL0  CL2  CL0  CL0  CL0  CL0  CL2  CL0  CL0\n",
       "4   5  0.49788  0.48246  1.98437  0.96082 -0.31685  0.73545 -1.63340 -0.45174 -0.30172  ...  CL1  CL0  CL0  CL1  CL0  CL0  CL2  CL2  CL0  CL0\n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading Drug consumption dataset and checking the heading for the first 5 raws\n",
    "URL='https://archive.ics.uci.edu/ml/machine-learning-databases/00373/drug_consumption.data'\n",
    "data = pd.read_csv(URL, header=None)\n",
    "data.columns = [\"v\"+str(x) for x in np.arange(0,32,1)]\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1885, 31)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking shape of data\n",
    "data.set_index(data.v0, inplace=True)\n",
    "data.drop('v0', axis=1, inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making traning set by spliting data \n",
    "x = data.iloc[:,0:12]\n",
    "y = data.iloc[:,14:15]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn accuracy:  0.6684350132625995\n",
      "forest accuracy:  0.6816976127320955\n"
     ]
    }
   ],
   "source": [
    "# Fiting multiclass classification models including Random Forest Classifier, MLP Classifier, and Multi Output Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "nn = MLPClassifier()\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "multi_nn = MultiOutputClassifier(nn, n_jobs=-1)\n",
    "multi_forest = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "\n",
    "multi_nn.fit(x_train, y_train)\n",
    "multi_forest.fit(x_train, y_train)\n",
    "\n",
    "print('nn accuracy: ', accuracy_score(y_test, multi_nn.predict(x_test)))\n",
    "print('forest accuracy: ', accuracy_score(y_test, multi_forest.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2514be17fa0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform a simple manual optimization for one of the default parameters for one of the previous models. \n",
    "# Plot the new obtained accuracy as a function of the chosen parameter.\n",
    "n_estimator = [20, 50, 100, 125, 150, 175,200, 250, 300]\n",
    "accuracy = []\n",
    "for es in n_estimator:\n",
    "    accuracy.append(accuracy_score(y_test, MultiOutputClassifier(RandomForestClassifier(n_estimators=es), n_jobs=-1).fit(x_train, y_train).predict(x_test)))\n",
    "\n",
    "plt.plot(n_estimator, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forest accuracy:  0.713527851458886\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "y = data.iloc[:,14:17]\n",
    "y[\"v15\"] = y[\"v15\"].apply(lambda x: 0 if x == 'CL2' else 1)\n",
    "y[\"v16\"] = y[\"v16\"].apply(lambda x: 0 if x == 'CL2' else 1)\n",
    "y[\"v17\"] = y[\"v17\"].apply(lambda x: 0 if x == 'CL2' else 1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "forest = KNeighborsClassifier(n_neighbors=3)\n",
    "multi_forest = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "multi_forest.fit(x_train, y_train)\n",
    "print('forest accuracy: ', accuracy_score(y_test, multi_forest.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run one binary classification model for 1 features out of 18. Test the performance of the model\n",
    "y = data.iloc[:,14:17]\n",
    "y[\"v15\"] = y[\"v15\"].apply(lambda x: 0 if x == 'CL2' else 1)\n",
    "y[\"v16\"] = y[\"v16\"].apply(lambda x: 0 if x == 'CL2' else 1)\n",
    "y[\"v17\"] = y[\"v17\"].apply(lambda x: 0 if x == 'CL2' else 1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "forest = RandomForestClassifier()\n",
    "multi_forest = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "multi_forest.fit(x_train, y_train)\n",
    "print('forest accuracy: ', accuracy_score(y_test, multi_forest.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forest accuracy:  0.583554376657825\n"
     ]
    }
   ],
   "source": [
    "# Run one binary classification model for 2 features out of 18. Test the performance of the model \n",
    "y = data.iloc[:,14:17]\n",
    "y[\"v15\"] = y[\"v15\"].apply(lambda x: 0 if x in ['CL2', 'CL3'] else 1)\n",
    "y[\"v16\"] = y[\"v16\"].apply(lambda x: 0 if x in ['CL2', 'CL3'] else 1)\n",
    "y[\"v17\"] = y[\"v17\"].apply(lambda x: 0 if x in ['CL2', 'CL3'] else 1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "forest = RandomForestClassifier()\n",
    "multi_forest = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "multi_forest.fit(x_train, y_train)\n",
    "print('forest accuracy: ', accuracy_score(y_test, multi_forest.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forest accuracy:  0.46419098143236076\n"
     ]
    }
   ],
   "source": [
    "# Run one binary classification model for 3 features out of 18. Test the performance of the model \n",
    "y = data.iloc[:,14:17]\n",
    "y[\"v15\"] = y[\"v15\"].apply(lambda x: 0 if x in ['CL2', 'CL3', 'CL4'] else 1)\n",
    "y[\"v16\"] = y[\"v16\"].apply(lambda x: 0 if x in ['CL2', 'CL3', 'CL4'] else 1)\n",
    "y[\"v17\"] = y[\"v17\"].apply(lambda x: 0 if x in ['CL2', 'CL3', 'CL4'] else 1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "forest = RandomForestClassifier()\n",
    "multi_forest = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "multi_forest.fit(x_train, y_train)\n",
    "print('forest accuracy: ', accuracy_score(y_test, multi_forest.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
